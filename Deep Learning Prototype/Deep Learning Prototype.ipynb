{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Deep Learning Prototype.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOszPGrRvlJr"
      },
      "source": [
        "# Car Pose Estimation - Deep Learning Prototype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjt-_L9pvlJy"
      },
      "source": [
        "David Besson - https://github.com/dhbesson/CarPoseML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qe6DsI8vlJz"
      },
      "source": [
        "## Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku3qXEcyvlJz"
      },
      "source": [
        "This notebook continues the develop of the machine learning framwork started in the first notebook - https://github.com/dhbesson/CarPoseML/blob/main/Data%20Wrangling/Data%20Wrangling.ipynb\n",
        "\n",
        "The 'Data Wrangling' created pytorch datasets based on the training/development/test images and labels provided by the Kaggle competition, \"Autonomous Driving: Can you predict the vehicle angle in different settings?\" - https://www.kaggle.com/c/pku-autonomous-driving\n",
        "\n",
        "This machine learning framework follows the solution proposed by Kaggle user Ruslan Baynazarov in his notebook \"CenterNet Baseline.\" - https://www.kaggle.com/hocop1/centernet-baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lWM7XzlvlJz"
      },
      "source": [
        "## Loading Datasets into PyTorch DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6enUx5QxvlJ0"
      },
      "source": [
        "The ability to efficiently load large datasets into memory is a crucial element of deep learning workflows. The PyTorch DataLoader class is one of the best solutions for that task. This blog post sumarizes the role of Pytorch Data Loaders:\n",
        "\n",
        "\"...\\[W\\]orking with large datasets requires loading them into memory all at once. This leads to memory outage and slowing down of programs. PyTorch offers a solution for parallelizing the data loading process with the support of automatic batching as well. This is the DataLoader class present within the torch.utils.data package.\"\n",
        "https://www.journaldev.com/36576/pytorch-dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9t0mYrFvlJ0"
      },
      "source": [
        "The last step in the 'Data Wrangling' notebook was to save the training, development, and test datasets with the Python pickle library. The first step here is to load those pickle files and then feed them into DataLoaders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAzOpYnCwBcj",
        "outputId": "75e6a904-3ce9-4101-bf45-46b239801e75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-6wdNg3wJtZ",
        "outputId": "faa9a24c-36d6-4378-f198-28a1d124a54e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! cd /content/drive/MyDrive/CarPoseML\r\n",
        "! git init\r\n",
        "! git pull https://github.com/dhbesson/CarPoseML.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 6330, done.\u001b[K\n",
            "remote: Total 6330 (delta 0), reused 0 (delta 0), pack-reused 6330\u001b[K\n",
            "Receiving objects: 100% (6330/6330), 4.43 GiB | 25.82 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n",
            "From https://github.com/dhbesson/CarPoseML\n",
            " * branch            HEAD       -> FETCH_HEAD\n",
            "Checking out files: 100% (6299/6299), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CnidB-avlJ0",
        "outputId": "92ac0f2c-5a37-4336-eaad-eb0dab2ba412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "import pickle\n",
        "from CarPoseUtils import *\n",
        "\n",
        "train_dataset = pickle.load(open(\"../Data Wrangling/datasets/train_dataset.p\", \"rb\"))\n",
        "dev_dataset = pickle.load(open(\"../Data Wrangling/datasets/dev_dataset.p\", \"rb\"))\n",
        "test_dataset = pickle.load(open(\"../Data Wrangling/datasets/test_dataset.p\", \"rb\"))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7451e858d656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mCarPoseUtils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data Wrangling/datasets/train_dataset.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdev_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data Wrangling/datasets/dev_dataset.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'CarPoseUtils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYEpurxbvlJ1"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "# Create data generators - they will produce batches\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "dev_loader = DataLoader(dataset=dev_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S0WBcXvvlJ1",
        "outputId": "e3c3816a-424c-47b6-8b60-9b65d44ddd8c"
      },
      "source": [
        "train_loader"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x181060b9ee0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfklgtQEvlJ2"
      },
      "source": [
        "from efficientnet_pytorch import EfficientNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd7pSzlmvlJ3"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class double_conv(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2'''\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
        "        super(up, self).__init__()\n",
        "\n",
        "        #  would be a nice idea if the upsampling could be learned too,\n",
        "        #  but my machine do not have enough memory to handle all those weights\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
        "\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2=None):\n",
        "        x1 = self.up(x1)\n",
        "        \n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n",
        "                        diffY // 2, diffY - diffY//2))\n",
        "        \n",
        "        # for padding issues, see \n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "        \n",
        "        if x2 is not None:\n",
        "            x = torch.cat([x2, x1], dim=1)\n",
        "        else:\n",
        "            x = x1\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "def get_mesh(batch_size, shape_x, shape_y):\n",
        "    mg_x, mg_y = np.meshgrid(np.linspace(0, 1, shape_y), np.linspace(0, 1, shape_x))\n",
        "    mg_x = np.tile(mg_x[None, None, :, :], [batch_size, 1, 1, 1]).astype('float32')\n",
        "    mg_y = np.tile(mg_y[None, None, :, :], [batch_size, 1, 1, 1]).astype('float32')\n",
        "    mesh = torch.cat([torch.tensor(mg_x).to(device), torch.tensor(mg_y).to(device)], 1)\n",
        "    return mesh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tH9uI-fvlJ3"
      },
      "source": [
        "class MyUNet(nn.Module):\n",
        "    '''Mixture of previous classes'''\n",
        "    def __init__(self, n_classes):\n",
        "        super(MyUNet, self).__init__()\n",
        "        self.base_model = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "        \n",
        "        self.conv0 = double_conv(5, 64)\n",
        "        self.conv1 = double_conv(64, 128)\n",
        "        self.conv2 = double_conv(128, 512)\n",
        "        self.conv3 = double_conv(512, 1024)\n",
        "        \n",
        "        self.mp = nn.MaxPool2d(2)\n",
        "        \n",
        "        self.up1 = up(1282 + 1024, 512)\n",
        "        self.up2 = up(512 + 512, 256)\n",
        "        self.outc = nn.Conv2d(256, n_classes, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        mesh1 = get_mesh(batch_size, x.shape[2], x.shape[3])\n",
        "        x0 = torch.cat([x, mesh1], 1)\n",
        "        x1 = self.mp(self.conv0(x0))\n",
        "        x2 = self.mp(self.conv1(x1))\n",
        "        x3 = self.mp(self.conv2(x2))\n",
        "        x4 = self.mp(self.conv3(x3))\n",
        "        \n",
        "        x_center = x[:, :, :, IMG_WIDTH // 8: -IMG_WIDTH // 8]\n",
        "        feats = self.base_model.extract_features(x_center)\n",
        "        bg = torch.zeros([feats.shape[0], feats.shape[1], feats.shape[2], feats.shape[3] // 8]).to(device)\n",
        "        feats = torch.cat([bg, feats, bg], 3)\n",
        "        \n",
        "        # Add positional info\n",
        "        mesh2 = get_mesh(batch_size, feats.shape[2], feats.shape[3])\n",
        "        feats = torch.cat([feats, mesh2], 1)\n",
        "        \n",
        "        x = self.up1(feats, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.outc(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XxwnI_yvlJ4",
        "outputId": "b4c4ef31-ba6f-44cf-cb97-8acb26658dc4"
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "# Gets the GPU if there is one, otherwise the cpu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "n_epochs = 10\n",
        "\n",
        "model = MyUNet(8).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=max(n_epochs, 10) * len(train_loader) // 3, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Loaded pretrained weights for efficientnet-b0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl5aHQ0CvlJ5"
      },
      "source": [
        "def criterion(prediction, mask, regr, size_average=True):\n",
        "    # Binary mask loss\n",
        "    pred_mask = torch.sigmoid(prediction[:, 0])\n",
        "#     mask_loss = mask * (1 - pred_mask)**2 * torch.log(pred_mask + 1e-12) + (1 - mask) * pred_mask**2 * torch.log(1 - pred_mask + 1e-12)\n",
        "    mask_loss = mask * torch.log(pred_mask + 1e-12) + (1 - mask) * torch.log(1 - pred_mask + 1e-12)\n",
        "    mask_loss = -mask_loss.mean(0).sum()\n",
        "    \n",
        "    # Regression L1 loss\n",
        "    pred_regr = prediction[:, 1:]\n",
        "    regr_loss = (torch.abs(pred_regr - regr).sum(1) * mask).sum(1).sum(1) / mask.sum(1).sum(1)\n",
        "    regr_loss = regr_loss.mean(0)\n",
        "    \n",
        "    # Sum\n",
        "    loss = mask_loss + regr_loss\n",
        "    if not size_average:\n",
        "        loss *= prediction.shape[0]\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB-qlGx4vlJ5"
      },
      "source": [
        "def train_model(epoch, history=None):\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (img_batch, mask_batch, regr_batch) in enumerate(tqdm(train_loader)):\n",
        "        img_batch = img_batch.to(device)\n",
        "        mask_batch = mask_batch.to(device)\n",
        "        regr_batch = regr_batch.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(img_batch)\n",
        "        loss = criterion(output, mask_batch, regr_batch)\n",
        "        if history is not None:\n",
        "            history.loc[epoch + batch_idx / len(train_loader), 'train_loss'] = loss.data.cpu().numpy()\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        exp_lr_scheduler.step()\n",
        "    \n",
        "    print('Train Epoch: {} \\tLR: {:.6f}\\tLoss: {:.6f}'.format(\n",
        "        epoch,\n",
        "        optimizer.state_dict()['param_groups'][0]['lr'],\n",
        "        loss.data))\n",
        "\n",
        "def evaluate_model(epoch, history=None):\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for img_batch, mask_batch, regr_batch in dev_loader:\n",
        "            img_batch = img_batch.to(device)\n",
        "            mask_batch = mask_batch.to(device)\n",
        "            regr_batch = regr_batch.to(device)\n",
        "\n",
        "            output = model(img_batch)\n",
        "\n",
        "            loss += criterion(output, mask_batch, regr_batch, size_average=False).data\n",
        "    \n",
        "    loss /= len(dev_loader.dataset)\n",
        "    \n",
        "    if history is not None:\n",
        "        history.loc[epoch, 'dev_loss'] = loss.cpu().numpy()\n",
        "    \n",
        "    print('Dev loss: {:.4f}'.format(loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVaBoau9vlJ5",
        "outputId": "da633d97-ba0b-49a7-888f-dca8bbfa1085"
      },
      "source": [
        "%%time\n",
        "import gc\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "history = pd.DataFrame()\n",
        "\n",
        "for epoch in range(1):\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    train_model(epoch, history)\n",
        "    evaluate_model(epoch, history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|                                           | 0/1055 [00:13<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\users\\dbesson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\users\\dbesson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\users\\dbesson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\dbesson\\Documents\\GitHub\\CarPoseML\\Deep Learning Prototype\\CarPoseUtils.py\", line 264, in __getitem__\n    img = preprocess_image(img0, flip=flip)\n  File \"C:\\Users\\dbesson\\Documents\\GitHub\\CarPoseML\\Deep Learning Prototype\\CarPoseUtils.py\", line 148, in preprocess_image\n    img = img[img.shape[0] // 2:]\nAttributeError: 'NoneType' object has no attribute 'shape'\n",
          "traceback": [
            "\u001b[1;31m--------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-11-67c6beef5998>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(epoch, history)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregr_batch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mimg_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mmask_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\dbesson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1164\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1165\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1166\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\dbesson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\dbesson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\dbesson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\dbesson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    393\u001b[0m             \u001b[1;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\users\\dbesson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\users\\dbesson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\users\\dbesson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\dbesson\\Documents\\GitHub\\CarPoseML\\Deep Learning Prototype\\CarPoseUtils.py\", line 264, in __getitem__\n    img = preprocess_image(img0, flip=flip)\n  File \"C:\\Users\\dbesson\\Documents\\GitHub\\CarPoseML\\Deep Learning Prototype\\CarPoseUtils.py\", line 148, in preprocess_image\n    img = img[img.shape[0] // 2:]\nAttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Mc4WHLvvlJ6",
        "outputId": "1c496473-f904-4a43-bc04-a339121bf3fc"
      },
      "source": [
        "train_dataset.root_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'../Data Collection/train_images/{}.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrHYqlwMvlJ6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}